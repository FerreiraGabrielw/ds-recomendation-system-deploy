{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Hybrid Recommender System for E-commerce (End-to-End)\"\n",
        "author: \"Gabriel Ferreira\"\n",
        "date: \"2025-12-19\"\n",
        "format:\n",
        "  html:\n",
        "    page-layout: full\n",
        "    code-fold: true\n",
        "    code-summary: \"Show Code\"\n",
        "    toc: true\n",
        "    toc-depth: 1\n",
        "    toc-title: \"Project Index\"\n",
        "    anchor-sections: false\n",
        "engine: jupytern\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "# Introduction\n",
        "\n",
        "Este projeto apresenta o desenvolvimento de um sistema de recomendação híbrido para e-commerce, cobrindo todo o ciclo de vida de uma solução de Machine Learning aplicada em contexto real de negócio.\n",
        "\n",
        "O objetivo central é aumentar conversão e ticket médio por meio de recomendações personalizadas, utilizando múltiplos sinais complementares:\n",
        "\n",
        "* comportamento histórico de compra (Collaborative Filtering),\n",
        "* similaridade semântica entre produtos (Content-Based),\n",
        "* padrões explícitos de coocorrência em cestas de compra (Association Rules).\n",
        "\n",
        "---\n",
        "\n",
        "# Project Structure\n",
        "\n",
        "O pipeline segue uma arquitetura end-to-end típica de sistemas de recomendação modernos:\n",
        "\n",
        "1. Definição do problema de negócio\n",
        "2. Criação do banco e ingestão dos dados\n",
        "3. Exploração e validação em SQL\n",
        "4. Limpeza e Pré Processamento\n",
        "5. Feature Engineering e Modelagem (CF, CB, AR)\n",
        "6. Construção do modelo híbrido\n",
        "7. Avaliação e Interpretação\n",
        "8. Preparação de artefatos\n",
        "9. Deploy (AWS S3, Lambda, API Gateway)\n",
        "\n",
        "Essa estrutura garante separação entre dados, modelos e inferência, facilitando manutenção e escalabilidade.\n",
        "\n",
        "---\n",
        "\n",
        "# Objetivos de Negócio\n",
        "\n",
        "Aumentar a relevância das recomendações para impulsionar:\n",
        "\n",
        "* AOV (Average Order Value),\n",
        "* taxa de conversão,\n",
        "* CTR de recomendações,\n",
        "* receita incremental.\n",
        "\n",
        "---\n",
        "\n",
        "# Data Sources & Modeling Assumptions\n",
        "\n",
        "Os dados utilizados representam um ambiente transacional típico de e-commerce, com tabelas normalizadas que refletem práticas de armazenamento e análise analítica.\n",
        "\n",
        "O dataset inclui:\n",
        "\n",
        "* histórico de transações em nível de item,\n",
        "* catálogo de produtos com atributos descritivos,\n",
        "* eventos de visualização de produtos,\n",
        "* informações demográficas básicas de clientes,\n",
        "* registros temporais para análise comportamental.\n",
        "\n",
        "---\n",
        "\n",
        "## Database Setup & SQL Exploration\n",
        "\n",
        "Antes de qualquer etapa de modelagem em Python, os dados passam por um processo de estruturação, ingestão e validação em banco de dados relacional, típicos de um ambiente real de analytics em e-commerce.\n",
        "\n",
        "### Entity-Relationship (ER) Diagram\n",
        "\n",
        "O diagrama abaixo ilustra o modelo relacional do banco, destacando entidades centrais como clientes, produtos, transações e visualizações, bem como seus relacionamentos.\n",
        "\n",
        "\n",
        "**Diagrama ER do banco de dados**\n",
        "\n",
        "![](ER-diagram.png)\n",
        "\n",
        "\n",
        "### Data Ingestion & Validation in MySQL\n",
        "\n",
        "Após a definição do schema, as tabelas são criadas e os dados são carregados diretamente no banco utilizando linha de comando e MySQL Workbench, reproduzindo práticas comuns de ingestão em ambientes analíticos.\n",
        "\n",
        "\n",
        "##### Criação do banco de dados e das tableas:\n",
        "<details>\n",
        "<summary><strong>Show SQL Schema</strong></summary>\n",
        "\n",
        "```sql\n",
        "-- =========================================================\n",
        "-- Criar banco de dados\n",
        "-- =========================================================\n",
        "CREATE DATABASE IF NOT EXISTS ecommerce_db\n",
        "  DEFAULT CHARACTER SET utf8mb4\n",
        "  DEFAULT COLLATE utf8mb4_unicode_ci;\n",
        "\n",
        "USE ecommerce_db;\n",
        "\n",
        "-- =========================================================\n",
        "-- Tabela: customers\n",
        "-- =========================================================\n",
        "CREATE TABLE IF NOT EXISTS customers (\n",
        "    customer_id INT UNSIGNED NOT NULL AUTO_INCREMENT,\n",
        "    name VARCHAR(100) NOT NULL,\n",
        "    email VARCHAR(150) UNIQUE,\n",
        "    gender ENUM('M','F','O') NULL,\n",
        "    age TINYINT UNSIGNED NULL,\n",
        "    city VARCHAR(100) NULL,\n",
        "    state VARCHAR(50) NULL,\n",
        "    registration_date DATETIME NOT NULL,\n",
        "    PRIMARY KEY (customer_id)\n",
        ") ENGINE=InnoDB;\n",
        "\n",
        "-- =========================================================\n",
        "-- Tabela: products\n",
        "-- =========================================================\n",
        "CREATE TABLE IF NOT EXISTS products (\n",
        "    product_id INT UNSIGNED NOT NULL AUTO_INCREMENT,\n",
        "    name VARCHAR(150) NOT NULL,\n",
        "    category VARCHAR(100) NOT NULL,\n",
        "    brand VARCHAR(100) NULL,\n",
        "    price DECIMAL(10,2) NOT NULL,\n",
        "    created_at DATETIME NOT NULL,\n",
        "    is_active TINYINT(1) NOT NULL DEFAULT 1,\n",
        "    PRIMARY KEY (product_id),\n",
        "    INDEX idx_products_category (category),\n",
        "    INDEX idx_products_brand (brand)\n",
        ") ENGINE=InnoDB;\n",
        "\n",
        "-- =========================================================\n",
        "-- Tabela: transactions\n",
        "-- =========================================================\n",
        "CREATE TABLE IF NOT EXISTS transactions (\n",
        "    transaction_id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,\n",
        "    customer_id INT UNSIGNED NOT NULL,\n",
        "    product_id INT UNSIGNED NOT NULL,\n",
        "    quantity INT UNSIGNED NOT NULL DEFAULT 1,\n",
        "    total_value DECIMAL(10,2) NOT NULL,\n",
        "    transaction_date DATETIME NOT NULL,\n",
        "    \n",
        "    PRIMARY KEY (transaction_id),\n",
        "    \n",
        "    INDEX idx_transactions_customer (customer_id),\n",
        "    INDEX idx_transactions_product (product_id),\n",
        "    INDEX idx_transactions_date (transaction_date),\n",
        "    \n",
        "    CONSTRAINT fk_transactions_customer\n",
        "        FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
        "        ON DELETE CASCADE,\n",
        "        \n",
        "    CONSTRAINT fk_transactions_product\n",
        "        FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
        "        ON DELETE RESTRICT\n",
        ") ENGINE=InnoDB;\n",
        "\n",
        "-- =========================================================\n",
        "-- Tabela: product_views\n",
        "-- =========================================================\n",
        "CREATE TABLE IF NOT EXISTS product_views (\n",
        "    view_id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,\n",
        "    customer_id INT UNSIGNED NOT NULL,\n",
        "    product_id INT UNSIGNED NOT NULL,\n",
        "    view_datetime DATETIME NOT NULL,\n",
        "    session_id VARCHAR(100) NULL,\n",
        "    device_type ENUM('desktop','mobile','tablet') NULL,\n",
        "    \n",
        "    PRIMARY KEY (view_id),\n",
        "    \n",
        "    INDEX idx_views_customer (customer_id),\n",
        "    INDEX idx_views_product (product_id),\n",
        "    INDEX idx_views_datetime (view_datetime),\n",
        "    \n",
        "    CONSTRAINT fk_views_customer\n",
        "        FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
        "        ON DELETE CASCADE,\n",
        "        \n",
        "    CONSTRAINT fk_views_product\n",
        "        FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
        "        ON DELETE RESTRICT\n",
        ") ENGINE=InnoDB;\n",
        "\n",
        "-- =========================================================\n",
        "-- Verificação final\n",
        "-- =========================================================\n",
        "SHOW TABLES;\n",
        "\n",
        "DESCRIBE customers;\n",
        "DESCRIBE products;\n",
        "DESCRIBE transactions;\n",
        "DESCRIBE product_views;\n",
        "```\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "##### Carregando dados no banco via linha de comando:\n",
        "\n",
        "{{< video SQL-DB-CREATION.mp4 >}}\n",
        "\n",
        "##### Execução de queries exploratórias iniciais:\n",
        "\n",
        "{{< video SQL-QUERIES.mp4 >}}\n",
        "\n",
        "---\n",
        "\n",
        "# EDA (Exploratory Data Analysis)"
      ],
      "id": "dd446212"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| include: false\n",
        "from getpass import getpass\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine, text\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "import pickle"
      ],
      "id": "9701019c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| include: false\n",
        "# Conectar no SQL\n",
        "DB_USER = \"root\"\n",
        "DB_HOST = \"127.0.0.1\"\n",
        "DB_PORT = 3306\n",
        "DB_NAME = \"ecommerce_db\"\n",
        "DB_PASS = \"sqlmala123\"\n",
        "\n",
        "CONN_STR = f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
        "engine = create_engine(CONN_STR, echo=False)\n",
        "\n",
        "# Pra reprodutibilidade\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "id": "af5cfcf6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Função Python para rodar SQL puro no notebook:"
      ],
      "id": "39d775dc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_sql_pure(sql: str, params: dict = None):\n",
        "    \"\"\"\n",
        "    Executa SQL puro (string) e retorna um pandas.DataFrame.\n",
        "    Exibe a query (útil para portfólio) e retorna o DataFrame.\n",
        "    \"\"\"\n",
        "    print(\"---- Executing SQL ----\")\n",
        "    print(sql.strip())\n",
        "    print(\"-----------------------\")\n",
        "    df = pd.read_sql_query(sql=text(sql), con=engine, params=params)\n",
        "    display(df.head(10))\n",
        "    return df\n",
        "\n",
        "# Configuração do matplotlib\n",
        "plt.rcParams['figure.figsize'] = (10,5)\n",
        "plt.rcParams['grid.linestyle'] = '--'"
      ],
      "id": "be3b2f64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "O primeiro passo da EDA é validar a integridade estrutural das tabelas.\n",
        "\n",
        "##### Contagens por tabela:"
      ],
      "id": "97fc65e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "SELECT \n",
        "  (SELECT COUNT(*) FROM customers) AS n_customers,\n",
        "  (SELECT COUNT(*) FROM products)  AS n_products,\n",
        "  (SELECT COUNT(*) FROM transactions) AS n_transactions,\n",
        "  (SELECT COUNT(*) FROM product_views) AS n_views;\n",
        "\"\"\"\n",
        "df = run_sql_pure(sql)\n",
        "vals = df.iloc[0].to_dict()\n",
        "names = list(vals.keys()); counts = list(vals.values())"
      ],
      "id": "b22f2ce1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Valores ausentes por tabela"
      ],
      "id": "a8ec9d98"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# lista de tabelas a verificar\n",
        "tables = ['customers', 'products', 'transactions', 'product_views']\n",
        "\n",
        "results = []\n",
        "for t in tables:\n",
        "    q_cols = f\"\"\"\n",
        "    SELECT COLUMN_NAME\n",
        "    FROM INFORMATION_SCHEMA.COLUMNS\n",
        "    WHERE TABLE_SCHEMA = '{DB_NAME}'\n",
        "      AND TABLE_NAME = '{t}'\n",
        "    ORDER BY ORDINAL_POSITION;\n",
        "    \"\"\"\n",
        "    cols_df = pd.read_sql_query(sql=text(q_cols), con=engine)\n",
        "    cols = cols_df['COLUMN_NAME'].tolist()\n",
        "    num_cols = len(cols)\n",
        "\n",
        "    # contar linhas\n",
        "    q_rows = f\"SELECT COUNT(*) AS n_rows FROM {t};\"\n",
        "    n_rows = pd.read_sql_query(sql=text(q_rows), con=engine).iloc[0,0]\n",
        "\n",
        "    if n_rows == 0 or num_cols == 0:\n",
        "        null_count = 0\n",
        "    else:\n",
        "        null_expr = \" + \".join([f\"SUM(`{c}` IS NULL)\" for c in cols])\n",
        "        q_nulls = f\"SELECT {null_expr} AS null_count FROM {t};\"\n",
        "        null_count = pd.read_sql_query(sql=text(q_nulls), con=engine).iloc[0,0]\n",
        "\n",
        "    total_cells = int(n_rows) * int(num_cols)\n",
        "    pct_null = (null_count / total_cells * 100) if total_cells > 0 else 0.0\n",
        "\n",
        "    results.append({\n",
        "        \"table\": t,\n",
        "        \"n_rows\": int(n_rows),\n",
        "        \"n_cols\": int(num_cols),\n",
        "        \"total_cells\": int(total_cells),\n",
        "        \"null_count\": int(null_count),\n",
        "        \"pct_null\": round(pct_null, 4)\n",
        "    })\n",
        "\n",
        "df_missing_tables = pd.DataFrame(results)\n",
        "display(df_missing_tables)"
      ],
      "id": "eed74852",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Duplicados e chaves (checar chave primária única)"
      ],
      "id": "149f8e26"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "SELECT \n",
        "  COUNT(*) AS total_rows,\n",
        "  COUNT(DISTINCT transaction_id) AS distinct_transaction_id,\n",
        "  COUNT(DISTINCT CONCAT(customer_id,'-',DATE(transaction_date))) AS distinct_cust_date\n",
        "FROM transactions;\n",
        "\"\"\"\n",
        "df = run_sql_pure(sql)\n",
        "print(df.to_string(index=False))"
      ],
      "id": "4d9f5b9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "Os resultados confirmam que os dados estão completos e consistentes, permitindo avançar para as análises sem necessidade de limpeza estrutural.\n",
        "\n",
        "---\n",
        "\n",
        "### Visualizações e Insights\n",
        "Nesta etapa, exploramos o comportamento do negócio por meio de SQL.\n",
        "\n",
        "##### Distribuição de preços - produtos"
      ],
      "id": "174ff518"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"SELECT price FROM products WHERE price IS NOT NULL;\"\n",
        "df_price = run_sql_pure(sql)\n",
        "df_price['price'] = pd.to_numeric(df_price['price'], errors='coerce')\n",
        "plt.hist(df_price['price'].dropna(), bins=30)\n",
        "plt.title(\"Product Price Distribuction\")\n",
        "plt.xlabel(\"Price\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "id": "43052a30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Top Produtos por quantidade e por receita"
      ],
      "id": "36c434eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "SELECT p.product_id, p.name,\n",
        "       SUM(t.quantity) AS total_qty,\n",
        "       SUM(t.total_value) AS total_revenue\n",
        "FROM transactions t\n",
        "JOIN products p ON t.product_id = p.product_id\n",
        "GROUP BY p.product_id\n",
        "ORDER BY total_qty DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "df_top = run_sql_pure(sql)\n",
        "ax = df_top.plot.bar(x='name', y='total_qty', legend=False)\n",
        "plt.xticks(rotation=70, fontsize=8)\n",
        "plt.title(\"Top 15 produtos por quantidade vendida\")\n",
        "plt.ylabel(\"Quantidade\")\n",
        "plt.show()\n",
        "\n",
        "# revenue bar\n",
        "df_top.plot.bar(x='name', y='total_revenue')\n",
        "plt.xticks(rotation=70, fontsize=8)\n",
        "plt.title(\"Top 15 produtos por receita (mesmos produtos)\")\n",
        "plt.ylabel(\"Receita\")\n",
        "plt.show()"
      ],
      "id": "021e1b5a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Vendas por mês"
      ],
      "id": "fe06aa7b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "SELECT DATE_FORMAT(transaction_date, '%Y-%m') AS ym,\n",
        "       COUNT(*) AS n_items,\n",
        "       SUM(total_value) AS revenue\n",
        "FROM transactions\n",
        "GROUP BY ym\n",
        "ORDER BY ym;\n",
        "\"\"\"\n",
        "df_ts = run_sql_pure(sql)\n",
        "df_ts['ym'] = pd.to_datetime(df_ts['ym'] + '-01')\n",
        "plt.plot(df_ts['ym'], df_ts['revenue'])\n",
        "plt.title(\"Receita por mês\")\n",
        "plt.xlabel(\"Mês\")\n",
        "plt.ylabel(\"Receita\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "23ede8a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### RFM - tabela e histogramas "
      ],
      "id": "c9bce149"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "WITH last AS (\n",
        "  SELECT customer_id,\n",
        "         DATEDIFF(CURDATE(), MAX(DATE(transaction_date))) AS recency_days,\n",
        "         COUNT(*) AS frequency,\n",
        "         SUM(total_value) AS monetary\n",
        "  FROM transactions\n",
        "  GROUP BY customer_id\n",
        ")\n",
        "SELECT * FROM last;\n",
        "\"\"\"\n",
        "df_rfm = run_sql_pure(sql)\n",
        "# Histograms\n",
        "fig, axes = plt.subplots(1,3, figsize=(15,4))\n",
        "axes[0].hist(df_rfm['recency_days'].dropna(), bins=20); axes[0].set_title('Recency (dias)')\n",
        "axes[1].hist(df_rfm['frequency'].dropna(), bins=20); axes[1].set_title('Frequency')\n",
        "axes[2].hist(df_rfm['monetary'].dropna(), bins=20); axes[2].set_title('Monetary')\n",
        "plt.show()\n",
        "\n",
        "# scatter recency x monetary\n",
        "plt.scatter(df_rfm['recency_days'], df_rfm['monetary'])\n",
        "plt.xlabel('Recency (dias)'); plt.ylabel('Monetary (total_spent)')\n",
        "plt.title('Recency x Monetary (clientes)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "1c4ffada",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Distribuição de compras por cliente "
      ],
      "id": "69fffe14"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "SELECT customer_id, COUNT(*) AS purchases\n",
        "FROM transactions\n",
        "GROUP BY customer_id;\n",
        "\"\"\"\n",
        "df_purchases = run_sql_pure(sql)\n",
        "plt.hist(df_purchases['purchases'], bins=30)\n",
        "plt.title(\"Distribuição de número de compras por cliente\")\n",
        "plt.xlabel(\"Número de compras\")\n",
        "plt.ylabel(\"Clientes\")\n",
        "plt.show()"
      ],
      "id": "bdee3ddc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Conversão views -> buys por produto"
      ],
      "id": "9e51ffcb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "SELECT p.product_id, p.name,\n",
        "  COALESCE(v.views,0) AS views,\n",
        "  COALESCE(b.buys,0)  AS buys,\n",
        "  ROUND(COALESCE(b.buys,0) / NULLIF(COALESCE(v.views,0),0) * 100,2) AS conversion_pct\n",
        "FROM products p\n",
        "LEFT JOIN (\n",
        "  SELECT product_id, COUNT(*) AS views\n",
        "  FROM product_views\n",
        "  GROUP BY product_id\n",
        ") v ON p.product_id = v.product_id\n",
        "LEFT JOIN (\n",
        "  SELECT product_id, COUNT(*) AS buys\n",
        "  FROM transactions\n",
        "  GROUP BY product_id\n",
        ") b ON p.product_id = b.product_id;\n",
        "\"\"\"\n",
        "df_conv = run_sql_pure(sql)\n",
        "plt.scatter(df_conv['views'], df_conv['buys'])\n",
        "plt.xlabel('Views'); plt.ylabel('Buys')\n",
        "plt.title('Views x Buys (produtos)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "3829e647",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Vendas por categoria "
      ],
      "id": "9cda4d40"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "SELECT p.category, COUNT(*) AS n_items, SUM(t.total_value) AS revenue\n",
        "FROM transactions t\n",
        "JOIN products p ON t.product_id = p.product_id\n",
        "GROUP BY p.category\n",
        "ORDER BY revenue DESC;\n",
        "\"\"\"\n",
        "df_cat = run_sql_pure(sql)\n",
        "df_cat.plot.bar(x='category', y='revenue')\n",
        "plt.title(\"Receita por categoria\")\n",
        "plt.xticks(rotation=60)\n",
        "plt.ylabel(\"Receita\")\n",
        "plt.show()"
      ],
      "id": "36ef7e54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### AOV (Average Order Value)"
      ],
      "id": "25691d8d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "SELECT customer_id, DATE(transaction_date) AS order_date, SUM(total_value) AS order_value\n",
        "FROM transactions\n",
        "GROUP BY customer_id, DATE(transaction_date);\n",
        "\"\"\"\n",
        "df_orders = run_sql_pure(sql)\n",
        "aov = df_orders['order_value'].mean()\n",
        "print(f\"AOV (média de valor por pedido - aproximação): R$ {aov:.2f}\")\n",
        "plt.hist(df_orders['order_value'], bins=30)\n",
        "plt.title(\"Distribuição do valor por pedido (aprox.)\")\n",
        "plt.xlabel(\"Order value\")\n",
        "plt.ylabel(\"Contagem\")\n",
        "plt.show()"
      ],
      "id": "c3303a32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Matriz cliente x produto - densidade (SPARSITY)"
      ],
      "id": "2fe4ed84"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sql = \"\"\"\n",
        "SELECT (SELECT COUNT(DISTINCT customer_id) FROM transactions) AS n_customers_active,\n",
        "       (SELECT COUNT(DISTINCT product_id) FROM transactions) AS n_products_sold,\n",
        "       (SELECT COUNT(*) FROM transactions) AS n_transactions;\n",
        "\"\"\"\n",
        "df_dim = run_sql_pure(sql)\n",
        "n_customers = int(df_dim['n_customers_active'].iloc[0])\n",
        "n_products = int(df_dim['n_products_sold'].iloc[0])\n",
        "n_trans = int(df_dim['n_transactions'].iloc[0])\n",
        "possible = n_customers * n_products\n",
        "sparsity = 1 - (n_trans / possible)\n",
        "print(f\"Clientes: {n_customers}, Produtos: {n_products}, Transações: {n_trans}\")\n",
        "print(f\"Sparsity (aprox): {sparsity:.6f}\")"
      ],
      "id": "b26de0b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Insights from EDA\n",
        "\n",
        "A análise revela padrões importantes:\n",
        "\n",
        "* alta concentração de vendas em poucas categorias,\n",
        "* clientes com frequência relativamente elevada,\n",
        "* sparsity alta (>90%) na matriz de interações.\n",
        "\n",
        "Esses achados justificam a escolha por:\n",
        "\n",
        "* modelos item-based em vez de user-based,\n",
        "* abordagem híbrida para mitigar limitações individuais.\n",
        "\n",
        "---\n",
        "\n",
        "# Criação dos Algoritimos\n",
        "\n",
        "Com base na EDA, foi definida uma arquitetura híbrida onde cada componente resolve um problema específico:\n",
        "\n",
        "| Componente        | Papel                                   |\n",
        "| ----------------- | --------------------------------------- |\n",
        "| Item-Item CF      | Personalização baseada em comportamento |\n",
        "| Content-Based     | Similaridade semântica e cold start     |\n",
        "| Association Rules | Cross-sell contextual                   |\n",
        "\n",
        "O objetivo não é substituir modelos, mas **combinar sinais complementares**.\n",
        "\n",
        "\n",
        "## Item-Item Collaborative Filtering\n",
        "\n",
        "Nesta etapa, construímos um sistema de recomendação baseado exclusivamente em padrões históricos de compra. O Item-Item CF recomenda itens semelhantes aos que o usuário já comprou, medindo similaridade entre itens a partir do comportamento dos usuários (quem comprou A também comprou B)."
      ],
      "id": "373b42f6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| include: false\n",
        "# Carregando Datasets\n",
        "customers = pd.read_csv(\"customers.csv\")\n",
        "products = pd.read_csv(\"products.csv\")\n",
        "transactions = pd.read_csv(\"transactions.csv\")\n",
        "views = pd.read_csv(\"product_views.csv\")"
      ],
      "id": "d5a3c8c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Criar dataset de interações (cliente x produto):"
      ],
      "id": "8f3c1388"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "interactions = (\n",
        "    transactions[['customer_id', 'product_id']]\n",
        "    .drop_duplicates()\n",
        ")\n",
        "interactions['interaction'] = 1\n",
        "interactions.head()"
      ],
      "id": "a6e5e356",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Construir a matriz Item x Cliente:"
      ],
      "id": "627d3007"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "item_user_matrix = interactions.pivot_table(\n",
        "    index='product_id',\n",
        "    columns='customer_id',\n",
        "    values='interaction',\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "item_user_matrix.shape"
      ],
      "id": "da8355b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Checar Sparsity:"
      ],
      "id": "e2fa7ff4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "density = item_user_matrix.values.sum() / item_user_matrix.size\n",
        "sparsity = 1 - density\n",
        "\n",
        "print(f\"Sparsity: {sparsity:.4f}\")"
      ],
      "id": "10824193",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Calcular Similaridade Item-Item (Cosine):"
      ],
      "id": "a80fc275"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "item_similarity = cosine_similarity(item_user_matrix)\n",
        "\n",
        "item_sim_df = pd.DataFrame(\n",
        "    item_similarity,\n",
        "    index=item_user_matrix.index,\n",
        "    columns=item_user_matrix.index\n",
        ")\n",
        "\n",
        "item_sim_df.iloc[:5, :5]"
      ],
      "id": "fbe575a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Co-ocorrência"
      ],
      "id": "83be551e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cooccurrence = item_user_matrix @ item_user_matrix.T"
      ],
      "id": "458834f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Shrinkage"
      ],
      "id": "0d97e325"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "LAMBDA = 10\n",
        "shrunk_similarity = item_sim_df * (cooccurrence / (cooccurrence + LAMBDA))"
      ],
      "id": "e3038154",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Função de Recomendação (Item-Item CF)"
      ],
      "id": "c502fa31"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Função de Recomendação (Item-Item CF)\n",
        "def recommend_item_item(user_id, k=10):\n",
        "    # Produtos comprados pelo usuário\n",
        "    bought_items = interactions.loc[\n",
        "        interactions['customer_id'] == user_id, 'product_id'\n",
        "    ].unique()\n",
        "\n",
        "    if len(bought_items) == 0:\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "    # Score médio de similaridade\n",
        "    scores = shrunk_similarity.loc[bought_items].mean(axis=0)\n",
        "\n",
        "    # Remover itens já comprados\n",
        "    scores = scores.drop(bought_items, errors='ignore')\n",
        "\n",
        "    return scores.sort_values(ascending=False).head(k)"
      ],
      "id": "0c5522ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Teste do modelo"
      ],
      "id": "b6b3c4c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_user = interactions['customer_id'].iloc[0]\n",
        "recommend_item_item(test_user, k=5)"
      ],
      "id": "1ff063d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Enriquecer com Informações do Produto"
      ],
      "id": "1f9b40b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def recommend_with_metadata(user_id, k=10):\n",
        "    recs = recommend_item_item(user_id, k)\n",
        "    \n",
        "    return (\n",
        "        recs\n",
        "        .reset_index()\n",
        "        .merge(products, on='product_id', how='left')\n",
        "        .rename(columns={0: 'score'})\n",
        "    )\n",
        "\n",
        "recommend_with_metadata(test_user, k=5)"
      ],
      "id": "b0364682",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "O modelo Item-Item Collaborative Filtering identifica produtos semelhantes a partir de padrões de compra reais, permitindo recomendações personalizadas e escaláveis. A aplicação de shrinkage reduz ruído causado por co-ocorrências raras, tornando o sistema mais confiável em cenários de alta esparsidade, típicos de e-commerce.\n",
        "\n",
        "O score gerado pelo Item-Item CF representa uma medida relativa de afinidade entre produtos, baseada exclusivamente em padrões históricos de compra. Ele é utilizado para ranquear itens recomendados e não deve ser interpretado como probabilidade absoluta.\n",
        "\n",
        "---\n",
        "\n",
        "# Content-Based Filtering (TF-IDF)\n",
        "\n",
        "Apesar da força do sinal comportamental, o CF apresenta limitações:\n",
        "\n",
        "| Limitação                | Impacto                          |\n",
        "| ------------------------ | -------------------------------- |\n",
        "| Cold start de produto    | Produto novo nunca é recomendado |\n",
        "| Dependência do histórico | Pouca explicação semântica       |\n",
        "| Sparsity alta            | Alguns itens quase não aparecem  |\n",
        "\n",
        "Para mitigar isso, utilizamos Content-Based Filtering, representando produtos por seus atributos textuais.\n",
        "\n",
        "##### Preparação do texto dos produtos:"
      ],
      "id": "2b9d8da1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "products_cb = products.copy()\n",
        "\n",
        "products_cb['text'] = (\n",
        "    products_cb['name'].fillna('') + ' ' +\n",
        "    products_cb['category'].fillna('') + ' ' +\n",
        "    products_cb['brand'].fillna('')\n",
        ")\n",
        "\n",
        "products_cb[['product_id', 'text']].head()"
      ],
      "id": "52678258",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Vetorização com TF-IDF:"
      ],
      "id": "b20d7bb1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2\n",
        ")\n",
        "\n",
        "tfidf_matrix = tfidf.fit_transform(products_cb['text'])\n",
        "\n",
        "tfidf_matrix.shape"
      ],
      "id": "1856fc62",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Similaridade entre produtos (Cosine):"
      ],
      "id": "abd462c9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "content_similarity = cosine_similarity(tfidf_matrix)"
      ],
      "id": "49e351c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Criar matriz Produto x Produto:"
      ],
      "id": "9dcdc57c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "content_sim_df = pd.DataFrame(\n",
        "    content_similarity,\n",
        "    index=products_cb['product_id'],\n",
        "    columns=products_cb['product_id']\n",
        ")\n",
        "\n",
        "content_sim_df.iloc[:5, :5]"
      ],
      "id": "4e045128",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Função de recomendação Content-Based:"
      ],
      "id": "0dc3cd17"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def recommend_content_based(user_id, k=10):\n",
        "    bought_items = interactions.loc[\n",
        "        interactions['customer_id'] == user_id, 'product_id'\n",
        "    ].unique()\n",
        "\n",
        "    if len(bought_items) == 0:\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "    scores = content_sim_df.loc[bought_items].mean(axis=0)\n",
        "    scores = scores.drop(bought_items, errors='ignore')\n",
        "\n",
        "    return scores.sort_values(ascending=False).head(k)"
      ],
      "id": "2673dc17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Teste do Content-Based:"
      ],
      "id": "6ef61007"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_user = interactions['customer_id'].iloc[0]\n",
        "recommend_content_based(test_user, k=5)"
      ],
      "id": "2b73738e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Enriquecer com informações do produto:"
      ],
      "id": "769a828b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def recommend_cb_with_metadata(user_id, k=10):\n",
        "    recs = recommend_content_based(user_id, k)\n",
        "    return (\n",
        "        recs\n",
        "        .reset_index()\n",
        "        .merge(products, on='product_id', how='left')\n",
        "        .rename(columns={0: 'score'})\n",
        "    )\n",
        "\n",
        "recommend_cb_with_metadata(test_user, k=5)"
      ],
      "id": "634225b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "O modelo baseado em conteúdo recomenda produtos semanticamente similares, ampliando a cobertura do sistema e permitindo recomendações mesmo para itens com pouco histórico.\n",
        "\n",
        "---\n",
        "\n",
        "# Offline Evaluation — CF vs CB\n",
        "\n",
        "Antes de combinar os modelos em uma abordagem híbrida, avaliamos separadamente o Item-Item Collaborative Filtering (CF) e o Content-Based Filtering (CB). Essa etapa é necessária para entender a contribuição individual de cada sinal, identificar suas forças e limitações e evitar que um modelo dominante mas ruidoso prejudique o desempenho final.\n",
        "\n",
        "A avaliação isolada permite comparar desempenho em métricas de ranking, ajustar pesos do modelo híbrido de forma fundamentada e justificar tecnicamente a escolha da arquitetura. Em cenários de e-commerce, essa prática garante que o modelo híbrido gere ganho incremental em relação aos baselines individuais, em vez de apenas misturar sinais sem benefício mensurável.\n",
        "\n",
        "##### Cria um split temporal do tipo Leave-Last-Out para avaliação:"
      ],
      "id": "6e79610e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "interactions_eval = transactions[['customer_id', 'product_id', 'transaction_date']].copy()\n",
        "\n",
        "# Garantir tipo datetime\n",
        "interactions_eval['transaction_date'] = pd.to_datetime(\n",
        "    interactions_eval['transaction_date']\n",
        ")\n",
        "\n",
        "# Ordenar temporalmente\n",
        "interactions_eval = interactions_eval.sort_values(\n",
        "    ['customer_id', 'transaction_date', 'product_id']\n",
        ")\n",
        "\n",
        "# Inicializar estruturas\n",
        "train_interactions = []\n",
        "test_interactions = {}\n",
        "\n",
        "# Holdout temporal (Last Item)\n",
        "for user_id, group in interactions_eval.groupby('customer_id'):\n",
        "    items = group['product_id'].tolist()\n",
        "\n",
        "    if len(items) < 2:\n",
        "        continue\n",
        "\n",
        "    test_item = items[-1]  # último item (mais recente)\n",
        "    test_interactions[user_id] = test_item\n",
        "\n",
        "    for item in items[:-1]:\n",
        "        train_interactions.append((user_id, item))\n",
        "\n",
        "train_df = pd.DataFrame(\n",
        "    train_interactions,\n",
        "    columns=['customer_id', 'product_id']\n",
        ")\n",
        "train_df['interaction'] = 1"
      ],
      "id": "857fa89f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Recriar a matriz Item x User para trein:"
      ],
      "id": "811ffb64"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "item_user_train = train_df.pivot_table(\n",
        "    index='product_id',\n",
        "    columns='customer_id',\n",
        "    values='interaction',\n",
        "    fill_value=0\n",
        ")"
      ],
      "id": "5e9ec6cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "#### Recalcular CF treino:"
      ],
      "id": "35c21461"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "item_sim_train = cosine_similarity(item_user_train)\n",
        "item_sim_train_df = pd.DataFrame(\n",
        "    item_sim_train,\n",
        "    index=item_user_train.index,\n",
        "    columns=item_user_train.index\n",
        ")"
      ],
      "id": "72de1fd2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Função de recomendação para avaliação (CF)"
      ],
      "id": "8f0d4230"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def recommend_cf_eval(user_id, k=10):\n",
        "    bought_items = train_df.loc[\n",
        "        train_df['customer_id'] == user_id, 'product_id'\n",
        "    ].unique()\n",
        "\n",
        "    if len(bought_items) == 0:\n",
        "        return []\n",
        "\n",
        "    scores = item_sim_train_df.loc[bought_items].mean(axis=0)\n",
        "    scores = scores.drop(bought_items, errors='ignore')\n",
        "\n",
        "    return scores.sort_values(ascending=False).head(k).index.tolist()"
      ],
      "id": "deb2ebd9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Função de recomendação para avaliação:"
      ],
      "id": "9f615973"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def recommend_cb_eval(user_id, k=10):\n",
        "    bought_items = train_df.loc[\n",
        "        train_df['customer_id'] == user_id, 'product_id'\n",
        "    ].unique()\n",
        "\n",
        "    if len(bought_items) == 0:\n",
        "        return []\n",
        "\n",
        "    scores = content_sim_df.loc[bought_items].mean(axis=0)\n",
        "    scores = scores.drop(bought_items, errors='ignore')\n",
        "\n",
        "    return scores.sort_values(ascending=False).head(k).index.tolist()"
      ],
      "id": "e9d1f676",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Avaliar Hit Rate @ K:"
      ],
      "id": "85eec768"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def hit_rate(model_func, k=10):\n",
        "    hits = 0\n",
        "    total = 0\n",
        "\n",
        "    for user_id in sorted(test_interactions.keys()):\n",
        "        true_item = test_interactions[user_id]\n",
        "\n",
        "        recs = model_func(user_id, k)\n",
        "\n",
        "        if true_item in recs:\n",
        "            hits += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    return hits / total"
      ],
      "id": "b99c8154",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Resultados — CF vs CB:"
      ],
      "id": "d4a3ccc1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for k in [5, 10]:\n",
        "    hr_cf = hit_rate(recommend_cf_eval, k)\n",
        "    hr_cb = hit_rate(recommend_cb_eval, k)\n",
        "\n",
        "    print(f\"Hit Rate @ {k}\")\n",
        "    print(f\"  Item-Item CF: {hr_cf:.4f}\")\n",
        "    print(f\"  Content-Based: {hr_cb:.4f}\")\n",
        "    print(\"-\" * 30)"
      ],
      "id": "bc158b77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "Antes da construção do modelo híbrido, avaliamos separadamente o desempenho do Item-Item Collaborative Filtering e do Content-Based Filtering utilizando uma estratégia Leave-One-Out e a métrica Hit Rate@K.\n",
        "\n",
        "Os resultados indicam que o modelo colaborativo apresenta maior capacidade preditiva, refletindo a força do sinal comportamental em dados implícitos. O Content-Based, embora com desempenho inferior isoladamente, mostrou-se consistente e adequado para complementar o sistema, especialmente em cenários de cold start e aumento de cobertura.\n",
        "\n",
        "**Conclusão**:\n",
        "O CF apresenta melhor desempenho isolado, enquanto o CB agrega valor incremental — justificando a combinação.\n",
        "\n",
        "# Hybrid Model — Weight Tuning\n",
        "\n",
        "Nesta etapa, testamos diferentes combinações de pesos entre CF e CB para maximizar performance.\n",
        "\n",
        "#### Vamos testar:\n",
        "\n",
        "| w_cf | w_cb |\n",
        "| ---- | ---- |\n",
        "| 0.0  | 1.0  |\n",
        "| 0.2  | 0.8  |\n",
        "| 0.4  | 0.6  |\n",
        "| 0.6  | 0.4  |\n",
        "| 0.8  | 0.2  |\n",
        "| 1.0  | 0.0  |\n",
        "\n",
        "\n",
        "Isso inclui:\n",
        "<br>\n",
        "* CB puro\n",
        "* CF puro\n",
        "* Híbridos intermediários\n",
        "\n",
        "##### Função utilitária de normalização:"
      ],
      "id": "94fb0880"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def min_max_normalize(scores: pd.Series):\n",
        "    if scores.empty:\n",
        "        return scores\n",
        "    return (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)"
      ],
      "id": "957ea75b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Função híbrida de recomendação:"
      ],
      "id": "17187b88"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def recommend_hybrid_eval(\n",
        "    user_id,\n",
        "    k=10,\n",
        "    w_cf=0.6,\n",
        "    w_cb=0.4\n",
        "):\n",
        "\n",
        "    bought_items = train_df.loc[\n",
        "        train_df['customer_id'] == user_id, 'product_id'\n",
        "    ].unique()\n",
        "\n",
        "    if len(bought_items) == 0:\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "    # CF\n",
        "    scores_cf = item_sim_train_df.loc[bought_items].mean(axis=0)\n",
        "    scores_cf = scores_cf.drop(bought_items, errors='ignore')\n",
        "    scores_cf = min_max_normalize(scores_cf)\n",
        "\n",
        "    # CB\n",
        "    scores_cb = content_sim_df.loc[bought_items].mean(axis=0)\n",
        "    scores_cb = scores_cb.drop(bought_items, errors='ignore')\n",
        "    scores_cb = min_max_normalize(scores_cb)\n",
        "\n",
        "    # Combinação\n",
        "    hybrid_scores = (\n",
        "        w_cf * scores_cf +\n",
        "        w_cb * scores_cb\n",
        "    ).dropna()\n",
        "\n",
        "    return hybrid_scores.sort_values(ascending=False).head(k)"
      ],
      "id": "fc923903",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Função de avaliação do híbrido:"
      ],
      "id": "06fe7f47"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def evaluate_hybrid(weights, k=10):\n",
        "    results = []\n",
        "\n",
        "    # Ordem fixa de usuários\n",
        "    users = sorted(test_interactions.keys())\n",
        "\n",
        "    for w_cf, w_cb in weights:\n",
        "        hits = []\n",
        "\n",
        "        for user in users:\n",
        "            true_item = test_interactions[user]\n",
        "\n",
        "            recs = recommend_hybrid_eval(\n",
        "                user_id=user,\n",
        "                k=k,\n",
        "                w_cf=w_cf,\n",
        "                w_cb=w_cb\n",
        "            )\n",
        "\n",
        "            hits.append(int(true_item in recs.index))\n",
        "\n",
        "        results.append({\n",
        "            'w_cf': w_cf,\n",
        "            'w_cb': w_cb,\n",
        "            f'hit_rate@{k}': np.mean(hits)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "id": "64f6ccbf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Rodar o tuning:"
      ],
      "id": "37c2c90f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "weight_grid = [\n",
        "    (0.0, 1.0),\n",
        "    (0.2, 0.8),\n",
        "    (0.4, 0.6),\n",
        "    (0.6, 0.4),\n",
        "    (0.8, 0.2),\n",
        "    (1.0, 0.0),\n",
        "]\n",
        "\n",
        "df_hybrid_eval = evaluate_hybrid(weight_grid, k=10)\n",
        "df_hybrid_eval.sort_values('hit_rate@10', ascending=False)"
      ],
      "id": "197cfb25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "\n",
        "A combinação dos modelos colaborativo e baseado em conteúdo resultou em melhoria de desempenho. O melhor resultado foi obtido com pesos w_cf=0.6 e w_cb=0.4, evidenciando que o sinal comportamental deve ser predominante, mas complementado por similaridade semântica.\n",
        "\n",
        "Esses resultados confirmam que o modelo híbrido captura múltiplas dimensões do comportamento do usuário, reduz limitações individuais dos modelos base e oferece um trade-off mais robusto entre precisão e cobertura.\n",
        "\n",
        "\n",
        "# Association Rules (Apriori)\n",
        "\n",
        "Além das abordagens colaborativa e baseada em conteúdo, o sistema incorpora Association Rules para capturar padrões explícitos de coocorrência em cestas de compra. Essa técnica permite identificar produtos frequentemente adquiridos juntos, sendo especialmente eficaz para estratégias de cross-sell e aumento do ticket médio.\n",
        "\n",
        "Diferentemente dos modelos centrados no usuário, as regras de associação operam diretamente sobre transações, tornando-se robustas a cenários de cold start de usuários e altamente interpretáveis para stakeholders de negócio. Integradas ao modelo híbrido, essas regras complementam a personalização com recomendações de produtos complementares.\n",
        " \n",
        "Analogia simples\n",
        "<br>\n",
        "\n",
        "* CF = sugerir outra camisa parecida\n",
        "* CB = sugerir camisa da mesma marca\n",
        "<br>\n",
        "Association Rules = sugerir o cinto que normalmente vai junto com a camisa\n",
        "\n",
        "Ou seja, responder a pergunta: O que costuma ser comprado junto?\n",
        "\n",
        "##### Criar as cestas:"
      ],
      "id": "47253b08"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Garantir que a coluna 'transaction_date' seja do tipo datetime\n",
        "transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'])\n",
        "\n",
        "# Criar uma coluna de \"order_id\"\n",
        "transactions['order_id'] = (\n",
        "    transactions['customer_id'].astype(str) + '_' +\n",
        "    transactions['transaction_date'].dt.date.astype(str)\n",
        ")\n",
        "\n",
        "# Agrupar produtos por pedido\n",
        "basket = (\n",
        "    transactions\n",
        "    .groupby('order_id')['product_id']\n",
        "    .apply(list)\n",
        ")\n",
        "\n",
        "basket.head()"
      ],
      "id": "f5d3d489",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### One-Hot Encoding das cestas:"
      ],
      "id": "1aa46963"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "te = TransactionEncoder()\n",
        "te_array = te.fit(basket).transform(basket)\n",
        "\n",
        "basket_df = pd.DataFrame(\n",
        "    te_array,\n",
        "    columns=te.columns_\n",
        ")\n",
        "\n",
        "basket_df.head()"
      ],
      "id": "6fbbf9f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Loop por categoria:"
      ],
      "id": "6a4126d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n"
      ],
      "id": "1aa2a662"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rules_all = []\n",
        "\n",
        "for category in products['category'].unique():\n",
        "\n",
        "    products_cat = products.loc[\n",
        "        products['category'] == category, 'product_id'\n",
        "    ].tolist()\n",
        "\n",
        "    basket_cat = basket.apply(\n",
        "        lambda items: [i for i in items if i in products_cat]\n",
        "    )\n",
        "\n",
        "    basket_cat = basket_cat[basket_cat.apply(len) >= 2]\n",
        "\n",
        "    if len(basket_cat) < 50:\n",
        "        continue\n",
        "\n",
        "    te = TransactionEncoder()\n",
        "    te_array = te.fit(basket_cat).transform(basket_cat)\n",
        "\n",
        "    basket_df_cat = pd.DataFrame(\n",
        "        te_array,\n",
        "        columns=te.columns_\n",
        "    )\n",
        "\n",
        "    frequent_itemsets = apriori(\n",
        "        basket_df_cat,\n",
        "        min_support=0.01,\n",
        "        use_colnames=True,\n",
        "        max_len=2\n",
        "    )\n",
        "\n",
        "    if frequent_itemsets.empty:\n",
        "        continue\n",
        "\n",
        "    rules = association_rules(\n",
        "        frequent_itemsets,\n",
        "        metric='lift',\n",
        "        min_threshold=1.0\n",
        "    )\n",
        "\n",
        "    if rules.empty:\n",
        "        continue\n",
        "\n",
        "    rules['category'] = category\n",
        "    rules_all.append(rules)"
      ],
      "id": "433a7ebf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Consolidar todas as regras:"
      ],
      "id": "2ac477a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rules_df = pd.concat(rules_all, ignore_index=True)\n",
        "rules_df.sort_values('lift', ascending=False).head(10)"
      ],
      "id": "ca881a55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Filtrar regras:"
      ],
      "id": "10baa20b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rules_filtered = rules_df[\n",
        "    (rules_df['antecedents'].apply(len) == 1) &\n",
        "    (rules_df['consequents'].apply(len) == 1) &\n",
        "    (rules_df['confidence'] >= 0.2) &\n",
        "    (rules_df['lift'] >= 1.2)\n",
        "].sort_values('lift', ascending=False)\n",
        "\n",
        "rules_filtered.head(10)"
      ],
      "id": "709e8409",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Função de recomendação — Association Rules por categoria:"
      ],
      "id": "0bddee13"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def recommend_association_by_category(user_id, k=5):\n",
        "\n",
        "    bought_items = interactions.loc[\n",
        "        interactions['customer_id'] == user_id, 'product_id'\n",
        "    ].unique()\n",
        "\n",
        "    if len(bought_items) == 0:\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "    recs = []\n",
        "\n",
        "    for item in bought_items:\n",
        "\n",
        "        item_category = products.loc[\n",
        "            products['product_id'] == item, 'category'\n",
        "        ].values[0]\n",
        "\n",
        "        matched_rules = rules_filtered[\n",
        "            (rules_filtered['category'] == item_category) &\n",
        "            (rules_filtered['antecedents'].apply(lambda x: item in x))\n",
        "        ]\n",
        "\n",
        "        for _, row in matched_rules.iterrows():\n",
        "            consequent = list(row['consequents'])[0]\n",
        "            recs.append((consequent, row['lift']))\n",
        "\n",
        "    if not recs:\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "    recs_df = pd.DataFrame(recs, columns=['product_id', 'score'])\n",
        "\n",
        "    return (\n",
        "        recs_df\n",
        "        .groupby('product_id')['score']\n",
        "        .max()\n",
        "        .sort_values(ascending=False)\n",
        "        .head(k)\n",
        "    )"
      ],
      "id": "0c474df3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Teste:"
      ],
      "id": "de705834"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "user_items = interactions.loc[\n",
        "    interactions['customer_id'] == test_user, 'product_id'\n",
        "].unique()\n",
        "\n",
        "user_items"
      ],
      "id": "3eb341c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "As regras de associação foram aplicadas como um sinal complementar de cross-sell, sendo utilizadas apenas quando o histórico do usuário intersecta os antecedentes das regras extraídas.\n",
        "\n",
        "# Final Hybrid Recommender\n",
        "\n",
        "O modelo final combina:\n",
        "\n",
        "| Componente        | Papel no sistema                        |\n",
        "| ----------------- | --------------------------------------- |\n",
        "| Item-Item CF      | Personalização baseada em comportamento |\n",
        "| Content-Based     | Similaridade semântica / cold start     |\n",
        "| Association Rules | Cross-sell contextual (checkout)        |\n",
        "<br>\n",
        "O híbrido não substitui, ele combina sinais.\n",
        "\n",
        "Obs: Cada modelo gera scores em escalas diferentes. Precisamos normalizar antes de somar.\n",
        "\n",
        "##### Função utilitária de normalização:"
      ],
      "id": "8e7181a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def min_max_normalize(scores: pd.Series):\n",
        "    if scores.empty:\n",
        "        return scores\n",
        "    return (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)"
      ],
      "id": "cd6bbdb0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Função de recomendação híbrida:"
      ],
      "id": "af6ed6f9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def recommend_hybrid(\n",
        "    user_id,\n",
        "    k=10,\n",
        "    w_cf=0.5,\n",
        "    w_cb=0.3,\n",
        "    w_ar=0.2\n",
        "):\n",
        "\n",
        "    scores_final = pd.Series(dtype=float)\n",
        "\n",
        "    # ---------- CF ----------\n",
        "    scores_cf = recommend_item_item(user_id, k=50)\n",
        "    scores_cf = min_max_normalize(scores_cf)\n",
        "\n",
        "    if not scores_cf.empty:\n",
        "        scores_final = scores_final.add(w_cf * scores_cf, fill_value=0)\n",
        "\n",
        "    # ---------- Content-Based ----------\n",
        "    scores_cb = recommend_content_based(user_id, k=50)\n",
        "    scores_cb = min_max_normalize(scores_cb)\n",
        "\n",
        "    if not scores_cb.empty:\n",
        "        scores_final = scores_final.add(w_cb * scores_cb, fill_value=0)\n",
        "\n",
        "    # ---------- Association Rules ----------\n",
        "    scores_ar = recommend_association_by_category(user_id, k=50)\n",
        "    scores_ar = min_max_normalize(scores_ar)\n",
        "\n",
        "    if not scores_ar.empty:\n",
        "        scores_final = scores_final.add(w_ar * scores_ar, fill_value=0)\n",
        "\n",
        "    # ---------- Remover itens já comprados ----------\n",
        "    bought_items = interactions.loc[\n",
        "        interactions['customer_id'] == user_id, 'product_id'\n",
        "    ].unique()\n",
        "\n",
        "    scores_final = scores_final.drop(bought_items, errors='ignore')\n",
        "\n",
        "    return scores_final.sort_values(ascending=False).head(k)"
      ],
      "id": "6cd536b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Teste do híbrido:"
      ],
      "id": "632d3532"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_user = interactions['customer_id'].iloc[0]\n",
        "recommend_hybrid(test_user, k=10)"
      ],
      "id": "3b59e84b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "##### Enriquecer com metadata:"
      ],
      "id": "da9789a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def recommend_hybrid_with_metadata(user_id, k=10):\n",
        "\n",
        "    recs = recommend_hybrid(user_id, k)\n",
        "\n",
        "    return (\n",
        "        recs\n",
        "        .reset_index()\n",
        "        .rename(columns={'index': 'product_id', 0: 'score'})\n",
        "        .merge(products, on='product_id', how='left')\n",
        "    )\n",
        "\n",
        "recommend_hybrid_with_metadata(test_user, k=10)"
      ],
      "id": "af359a9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "O sistema final combina três sinais complementares: Item-Item Collaborative Filtering, Content-Based Filtering e Association Rules. Cada componente atua em um aspecto distinto do problema, garantindo personalização, cobertura e capacidade de cross-sell. As pontuações são normalizadas e combinadas por meio de uma soma ponderada, permitindo ajuste fino do impacto de cada sinal.\n",
        "\n",
        "O modelo analisa o histórico do cliente, a similaridade entre produtos e padrões recorrentes de compra conjunta para gerar recomendações personalizadas e contextualizadas, equilibrando relevância individual e oportunidades de aumento de ticket médio. Ou seja, em cenários onde não há correspondência, o sistema não força recomendações artificiais, preservando a qualidade do ranking.\n",
        "\n",
        "# Conclusão\n",
        "\n",
        "Foi desenvolvido um sistema híbrido de recomendação que combina sinais comportamentais (Item-Item Collaborative Filtering), semânticos (Content-Based Filtering) e contextuais (Association Rules). A arquitetura garante cobertura, personalização e capacidade de cross-sell, respeitando limitações estatísticas dos dados e evitando recomendações artificiais. O modelo reflete práticas reais de produção e foi avaliado de forma incremental, demonstrando ganhos qualitativos em relevância e interpretabilidade.\n",
        "\n",
        "## Cloud Deployment (AWS)\n",
        "\n",
        "Esta etapa final transforma o modelo desenvolvido em um serviço utilizável em produção, seguindo treinamento offline, artefatos versionados, e inferência online via arquitetura serverless.\n",
        "\n",
        "O deploy foi organizado em duas grandes fases:\n",
        "\n",
        "## 1️. Offline Artifacts — Preparação do Modelo para Produção\n",
        "\n",
        "Antes de qualquer interação com a infraestrutura cloud, o sistema de recomendação é congelado em artefatos estáticos, treinados e validados offline.\n",
        "\n",
        "Essa abordagem segue um padrão amplamente utilizado em sistemas reais de recomendação:\n",
        "\n",
        "> *O treinamento ocorre offline.\n",
        "> Em produção, a API apenas carrega artefatos e executa ranking.*\n",
        "\n",
        "### O que é salvo como artefato\n",
        "\n",
        "OS arquivos que representam o estado final do modelo, garantindo:\n",
        "\n",
        "* Reprodutibilidade\n",
        "* Baixo custo computacional em produção\n",
        "* Baixa latência de resposta\n",
        "* Separação entre treino e inferência\n",
        "\n",
        "##### Salvar artefatos finais do modelo híbrido construído:"
      ],
      "id": "29a865f9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -------------------------\n",
        "# Criar diretório de artefatos\n",
        "# -------------------------\n",
        "ARTIFACTS_DIR = \"artifacts\"\n",
        "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# 1️⃣ CF — Similaridade Item-Item\n",
        "# -------------------------\n",
        "with open(f\"{ARTIFACTS_DIR}/cf_similarity.pkl\", \"wb\") as f:\n",
        "    pickle.dump(shrunk_similarity, f)\n",
        "\n",
        "# -------------------------\n",
        "# 2️⃣ Content-Based — Similaridade TF-IDF\n",
        "# -------------------------\n",
        "with open(f\"{ARTIFACTS_DIR}/cb_similarity.pkl\", \"wb\") as f:\n",
        "    pickle.dump(content_sim_df, f)\n",
        "\n",
        "# -------------------------\n",
        "# 3️⃣ Association Rules\n",
        "# -------------------------\n",
        "with open(f\"{ARTIFACTS_DIR}/association_rules.pkl\", \"wb\") as f:\n",
        "    pickle.dump(rules_filtered, f)\n",
        "\n",
        "# -------------------------\n",
        "# 4️⃣ Products (metadata)\n",
        "# -------------------------\n",
        "products.to_parquet(f\"{ARTIFACTS_DIR}/products.parquet\", index=False)\n",
        "\n",
        "# -------------------------\n",
        "# 5️⃣ Interactions (histórico mínimo)\n",
        "# -------------------------\n",
        "interactions.to_parquet(f\"{ARTIFACTS_DIR}/interactions.parquet\", index=False)\n",
        "\n",
        "# -------------------------\n",
        "# Versões para deploy\n",
        "# -------------------------\n",
        "products.to_csv(f\"{ARTIFACTS_DIR}/products.csv\", index=False)\n",
        "interactions.to_csv(f\"{ARTIFACTS_DIR}/interactions.csv\", index=False)"
      ],
      "id": "465c8cb0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Deploy na AWS\n",
        "\n",
        "Com os artefatos prontos, o sistema é implantado em uma arquitetura serverless na AWS, composta por três serviços principais:\n",
        "\n",
        "* **Amazon S3** → armazenamento e versionamento dos artefatos\n",
        "* **AWS Lambda** → execução da inferência sob demanda\n",
        "* **Amazon API Gateway** → exposição do modelo via endpoint REST\n",
        "\n",
        "---\n",
        "\n",
        "### Amazon S3 — Armazenamento dos Artefatos do Modelo\n",
        "\n",
        "Na primeira etapa da implantação cloud, é criado um bucket S3, responsável por armazenar todos os artefatos do modelo.\n",
        "\n",
        "\n",
        "\n",
        "O S3 atua como a **camada de armazenamento de modelos**, desacoplada da lógica de inferência.\n",
        "\n",
        "##### Criação do bucket e upload dos artefatos no S3:\n",
        "\n",
        "{{< video AWS1-S3-bucket-creation.mp4 >}}\n",
        "\n",
        "---\n",
        "\n",
        "### AWS Lambda — Servindo o Recomendador\n",
        "\n",
        "Com os artefatos disponíveis no S3, foi criada uma função AWS Lambda responsável por:\n",
        "\n",
        "* Carregar os artefatos na inicialização\n",
        "* Receber requisições com `user_id`\n",
        "* Executar o ranking híbrido (CF + CB + Association Rules)\n",
        "* Retornar recomendações em formato JSON\n",
        "\n",
        "Essa separação garante que a Lambda execute somente inferência, mantendo custo e complexidade controlados.\n",
        "\n",
        "\n",
        "##### Criação e configuração da função Lambda:\n",
        "\n",
        "{{< video AWS2_FuncaoLambda.mp4 >}}\n",
        "\n",
        "##### Configuração da Layer:\n",
        "\n",
        "{{< video AWS3_Layer.mp4 >}}\n",
        "\n",
        "#### Teste da Função:\n",
        "\n",
        "{{< video AWS4-TesteFuncao.mp4 >}}\n",
        "\n",
        "### API Gateway — Exposição do Modelo via API REST\n",
        "\n",
        "Para tornar o sistema acessível externamente, a função Lambda é integrada ao Amazon API Gateway.\n",
        "\n",
        "O resultado é um endpoint REST capaz de retornar recomendações personalizadas sob demanda, pronto para consumo por:\n",
        "\n",
        "* Frontend web\n",
        "* Aplicações mobile\n",
        "* Sistemas internos de e-commerce\n",
        "\n",
        "##### Criação da API no API Gateway e integração com Lambda:\n",
        "\n",
        "{{< video AWS5-API-Gateway.mp4 >}}\n",
        "\n",
        "---\n",
        "\n",
        "### Deploy Final e Demonstração End-to-End:\n",
        "\n",
        "Após a configuração do S3, Lambda e API Gateway, o sistema é implantado e testado de ponta a ponta.\n",
        "\n",
        "##### Criação do bucket para UI demo:\n",
        "\n",
        "{{< video AWS6-BucketUI-DEMO.mp4 >}}\n",
        "\n",
        "##### Demonstração — Deploy final e chamada da API de recomendação:\n",
        "\n",
        "{{< video AWS7-FINAL-DMEO.mp4 >}}\n",
        "\n",
        "---\n",
        "\n",
        "Essa abordagem permite evoluir o modelo (re-treino, novos pesos, novos sinais) sem impactar a API, bastando substituir os artefatos no S3.\n",
        "\n",
        "---\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "Este projeto demonstra a construção de um sistema de recomendação híbrido, interpretável e orientado à produção, combinando rigor técnico com impacto direto no negócio.\n",
        "\n",
        "A abordagem híbrida permite equilibrar personalização, cobertura e oportunidades de cross-sell, refletindo práticas reais adotadas em plataformas de e-commerce em escala.\n",
        "\n",
        "---\n",
        "\n",
        "## GitHub Repository\n",
        "\n",
        "[Link para o repositório]\n",
        "\n",
        "---\n"
      ],
      "id": "2ef1e1f9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\gabri\\anaconda3\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}